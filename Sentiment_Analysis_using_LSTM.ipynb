{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment_Analysis_using_LSTM.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOZLpusLVU/HYwR0tNCLmSj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aayush360/Natural_langauge_processing/blob/main/Sentiment_Analysis_using_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PujIjtSPn-4z"
      },
      "source": [
        "https://www.youtube.com/watch?v=CcGf_Uo7NMw&list=PL1w8k37X_6L_s4ncq-swTBvKDWnRSrinI&index=13\n",
        "\n",
        "link to video tutorial: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAiFPk86fPGb"
      },
      "source": [
        "# one-hot representation"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9d_wjFWidvh",
        "outputId": "c6aae7e8-ad8a-40d7-cfb3-4e526444ff2d"
      },
      "source": [
        "from keras.preprocessing.text import one_hot\n",
        "\n",
        "# define documents\n",
        "\n",
        "docs =['glass of orange juice',\n",
        "       'bottle of mango juice',\n",
        "       'glass of mango shake',\n",
        "       'drink bottle of banana shake',\n",
        "       'I want a glass of cold water',\n",
        "       'The king and the queen',\n",
        "       'man and women']\n",
        "\n",
        "\n",
        "vocab_size = 10000\n",
        "encoded_docs = [one_hot(d,vocab_size) for d in docs]\n",
        "print(encoded_docs)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[8840, 7764, 3228, 4611], [3464, 7764, 7858, 4611], [8840, 7764, 7858, 7187], [3145, 3464, 7764, 6970, 7187], [2476, 172, 2511, 8840, 7764, 1825, 9530], [259, 1835, 6154, 259, 7153], [5710, 6154, 4803]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnqhmfLGi9OT"
      },
      "source": [
        "## Word-Embeddings"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJ3CrCNbjciU",
        "outputId": "247e9fc8-e2c4-4bb5-b27d-95236578149d"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "embedding_length = 5\n",
        "max_doc_length = 10\n",
        "\n",
        "encoded_docs = pad_sequences(encoded_docs,maxlen=max_doc_length,truncating='post',padding='post')\n",
        "print(encoded_docs)\n",
        "\n",
        "# each document will now have length of 10\n",
        "# and embedding vector size is 5, and each word will be denoted by vector of size of 5"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[8840 7764 3228 4611    0    0    0    0    0    0]\n",
            " [3464 7764 7858 4611    0    0    0    0    0    0]\n",
            " [8840 7764 7858 7187    0    0    0    0    0    0]\n",
            " [3145 3464 7764 6970 7187    0    0    0    0    0]\n",
            " [2476  172 2511 8840 7764 1825 9530    0    0    0]\n",
            " [ 259 1835 6154  259 7153    0    0    0    0    0]\n",
            " [5710 6154 4803    0    0    0    0    0    0    0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bS2gxxajrxH"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size,embedding_length, input_length=max_doc_length))\n",
        "\n",
        "model.add(LSTM(units=64)) # output of LSTM is 7x64 , 7 doc each represeted by vector of length 64\n",
        "\n",
        "model.compile('rmsprop','mse')\n",
        "\n",
        "model.summary()\n",
        "\n",
        "output = model.predict(encoded_docs)\n",
        "print(output.shape)\n",
        "print(output) # 7 docs, each sentence/doc has 10 words, and each word represented by vecotor of length 5 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nm-35berli-3"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    }
  ]
}