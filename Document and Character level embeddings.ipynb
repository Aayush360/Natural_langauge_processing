{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an unsupervised algorithm that learns fixed-length feature representations from variable-length pieces of texts, \n",
    "# such as\n",
    "# sentences, paragraphs, and documents. Our algorithm represents each document by a dense vector which is trained \n",
    "#to predict words in the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec,TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the training corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['human', 'interface', 'computer'],\n",
       " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
       " ['eps', 'user', 'interface', 'system'],\n",
       " ['system', 'human', 'system', 'eps'],\n",
       " ['user', 'response', 'time'],\n",
       " ['trees'],\n",
       " ['graph', 'trees'],\n",
       " ['graph', 'minors', 'trees'],\n",
       " ['graph', 'minors', 'survey']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will convert the tokenized documents into tagged-documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['human', 'interface', 'computer'], tags=[0]),\n",
       " TaggedDocument(words=['survey', 'user', 'computer', 'system', 'response', 'time'], tags=[1]),\n",
       " TaggedDocument(words=['eps', 'user', 'interface', 'system'], tags=[2]),\n",
       " TaggedDocument(words=['system', 'human', 'system', 'eps'], tags=[3]),\n",
       " TaggedDocument(words=['user', 'response', 'time'], tags=[4]),\n",
       " TaggedDocument(words=['trees'], tags=[5]),\n",
       " TaggedDocument(words=['graph', 'trees'], tags=[6]),\n",
       " TaggedDocument(words=['graph', 'minors', 'trees'], tags=[7]),\n",
       " TaggedDocument(words=['graph', 'minors', 'survey'], tags=[8])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = [TaggedDocument(doc,[i]) for i,doc in enumerate(common_texts)]\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doc2Vec expects a list of tokens as input for each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's build and train basic Doc2Vec model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(documents,vector_size=5,min_count=1,workers=4, epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(documents,total_examples = model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each document will be represented by a vector of five floating-point values.\n",
    "# only terms that occur at least min_count number of times will be considered in the vocabulary.\n",
    "# number of threads to be used while training to speed up the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.wv.key_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'system': 0,\n",
       " 'graph': 1,\n",
       " 'trees': 2,\n",
       " 'user': 3,\n",
       " 'minors': 4,\n",
       " 'eps': 5,\n",
       " 'time': 6,\n",
       " 'response': 7,\n",
       " 'survey': 8,\n",
       " 'computer': 9,\n",
       " 'interface': 10,\n",
       " 'human': 11}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.key_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building a document vector for a new sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00217576, -0.04548197, -0.03271691, -0.09795582, -0.06015328],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = model.infer_vector(['user','interface','for','computer'])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.corpus_count # how many documents is the model trained with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing Vector size and min_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us built doc2vec model with vectorsize of 50 and min_count parameter set to 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(documents,vector_size=50,min_count=3,epochs=40)\n",
    "model.train(documents,total_examples=model.corpus_count,epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.wv.key_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'system': 0, 'graph': 1, 'trees': 2, 'user': 3}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.key_to_index # here only words having minimum freq of 3 in the total corpus were considered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00045011 -0.00428057 -0.00265949 -0.00928813 -0.00611875  0.00621604\n",
      " -0.00886304 -0.00055536  0.0060769   0.00585221  0.00437172 -0.00416743\n",
      " -0.00106433  0.00950826  0.00108614  0.00951415  0.00881194  0.00165049\n",
      "  0.00996538 -0.00823202 -0.00739136 -0.00375222  0.00100804  0.00483836\n",
      " -0.00078981 -0.00267532  0.00833382 -0.00716673 -0.00849993 -0.00057538\n",
      " -0.00774354  0.00789681 -0.00271049  0.01000315 -0.0011322   0.00955895\n",
      " -0.00095618  0.00871789 -0.00894057  0.00494313 -0.00680891 -0.00928201\n",
      "  0.00455901  0.00222068 -0.00302778  0.00211217 -0.00469394 -0.00836468\n",
      " -0.0031305  -0.00807102]\n"
     ]
    }
   ],
   "source": [
    "vector = model.infer_vector(['user','interface','for','computer'])\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is our paragraph vector\n",
    "# the size of vector is 50 though there are only 4 terms are in the vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are tow popular approach to build paragraph vectors\n",
    "# PV-DM, PV-DBOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the dm paramter for switchig between modeling approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when dm=1, distributed memory approach\n",
    "# when dm=0, distributed bag of word approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(documents,vector_size=50,min_count=2,epochs=40,dm=1)\n",
    "model.train(documents, total_examples=model.corpus_count, epochs = model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.9349295e-04 -4.4075958e-03 -3.0497687e-03 -9.3083568e-03\n",
      " -6.3402513e-03  6.3978978e-03 -9.1088917e-03 -9.2215640e-05\n",
      "  5.4598744e-03  6.1668139e-03  4.7003049e-03 -3.6173128e-03\n",
      " -8.3109201e-04  9.1717634e-03  1.3813858e-03  8.9835059e-03\n",
      "  8.8255377e-03  1.9142296e-03  9.3122525e-03 -8.3465176e-03\n",
      " -7.7758809e-03 -3.7051956e-03  7.2509644e-04  5.0154338e-03\n",
      " -8.8647025e-04 -2.6348645e-03  7.9512224e-03 -7.8090215e-03\n",
      " -8.4188618e-03 -8.4397587e-04 -7.1763806e-03  8.3678029e-03\n",
      " -3.3651828e-03  9.8766657e-03 -1.1650656e-03  9.9916318e-03\n",
      " -1.0872122e-03  8.1198551e-03 -8.7413434e-03  4.8681051e-03\n",
      " -7.2452938e-03 -8.8497410e-03  4.3714978e-03  1.6152665e-03\n",
      " -3.3612733e-03  2.4591167e-03 -4.4178534e-03 -8.3774794e-03\n",
      " -2.7117245e-03 -8.2320301e-03]\n"
     ]
    }
   ],
   "source": [
    "vector = model.infer_vector(['user','interface','for','computer'])\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(documents,vector_size=50,min_count=2,epochs=40,dm=0)\n",
    "model.train(documents,total_examples=model.corpus_count,epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.51261990e-03 -4.63405671e-03 -3.65272630e-03 -9.65321902e-03\n",
      " -6.80024642e-03  6.81753457e-03 -9.61384457e-03  9.70871712e-04\n",
      "  4.80194576e-03  6.96728472e-03  5.10881562e-03 -2.65987264e-03\n",
      " -3.51611496e-04  8.70065391e-03  2.11652718e-03  8.22698232e-03\n",
      "  8.14919453e-03  2.08939565e-03  8.67329352e-03 -8.13122466e-03\n",
      " -8.40026885e-03 -3.65634984e-03 -3.69181835e-05  5.06948819e-03\n",
      " -1.16028322e-03 -2.40938179e-03  7.49177812e-03 -8.96984804e-03\n",
      " -8.41754582e-03 -1.05946395e-03 -6.11592317e-03  9.35982727e-03\n",
      " -4.61108750e-03  1.02405492e-02 -1.38859160e-03  1.10740885e-02\n",
      " -1.57870154e-03  7.43725058e-03 -8.41030292e-03  4.65027709e-03\n",
      " -8.00203346e-03 -8.00907519e-03  4.03361348e-03  7.91331637e-04\n",
      " -4.42849845e-03  3.30409384e-03 -3.83381685e-03 -8.21210537e-03\n",
      " -2.02311412e-03 -8.53967294e-03]\n"
     ]
    }
   ],
   "source": [
    "vector = model.infer_vector(['user','interface','for','computer'])\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The distributed memory model takes word vectors into account and comes with two additional parameters,\n",
    "#dm_concat and dm_mean.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indicates to the algorithm that the context vectors should be concatenated while trying to predict the target word.\n",
    "# This, of course, leads to building a larger model since multiple word embeddings get concatenated.\n",
    "\n",
    "# The window size parameter controls the distance between the word under concentration and the word to be predicted,\n",
    "# initial learning rate can be specified using the alpha parameter\n",
    "# min_alpha- what value the learning rate should drop to over the course of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(documents,vector_size=50,min_count=2,epochs=40, window=2,dm=1,dm_concat=1,alpha=0.3,min_alpha=0.05)\n",
    "model.train(documents,total_examples=model.corpus_count,epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.50854525e-02 -2.06051767e-01 -1.15051866e-01  1.61393196e-04\n",
      "  1.48151055e-01  7.69819841e-02  1.94396619e-02 -2.61510372e-01\n",
      "  1.47296200e-02  1.72400221e-01 -1.03294447e-01 -1.41764833e-02\n",
      " -1.79328769e-01 -1.58353925e-01 -1.14882970e-02 -1.46243125e-01\n",
      "  5.05606569e-02  7.99241960e-02 -3.40881161e-02 -2.03332707e-01\n",
      " -1.22323632e-04  1.61011219e-02 -9.09983665e-02  3.37552801e-02\n",
      " -2.39929393e-01 -8.70695561e-02 -2.62958497e-01 -2.02713106e-02\n",
      "  6.73472807e-02 -1.70263305e-01  1.73107237e-01 -2.00216919e-02\n",
      "  6.06580377e-02 -1.98573694e-01  9.53349099e-02 -1.42446518e-01\n",
      "  5.88329472e-02 -1.05561122e-01 -1.49081983e-02  4.25416231e-02\n",
      "  1.99918240e-01 -2.58556753e-02  2.30551079e-01 -2.17566103e-01\n",
      "  4.46799025e-02 -7.29657933e-02  4.57035787e-02 -1.49397757e-02\n",
      "  5.45404106e-03 -1.58229351e-01]\n"
     ]
    }
   ],
   "source": [
    "vector=model.infer_vector(['user','interface','for','computer'])\n",
    "print(vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the dm_mean parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two alternative approaches are to sum or average the context vectors instead of concatenating them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When the dm_mean parameter is set to 1, the mean of the context word vectors is taken.\n",
    "# The sum of the context word vectors is taken into account when dm_mean is set to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(documents,vector_size=50,min_count=2,epochs=40, window=2,dm=1,dm_concat=0,dm_mean=1,alpha=0.3,min_alpha=0.05)\n",
    "model.train(documents,total_examples=model.corpus_count,epochs=model.epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
