{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# he neighborhood of a word carries important information in terms of what context the word is carrying in a sentence.\n",
    "# The relationship between the word and its neighborhood tends to define the semantics of a word and its overall \n",
    "# positioning and presence in a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2vec captures relationships in text; consequently, similar words have similar representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relationship of Man:King is the same as Woman:Queen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2vec uses a simple neural network to build this architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2vec is an unsupervised methodology for building word embeddings. In the\n",
    "# Word2vec architecture, an attempt is made to do either of the following:\n",
    "# Predict the target word based on the context word \n",
    "# Predict the context word based on the target word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are two main learning algorithms in word2vec : continuous bag-of-words and continuous skip-gram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.0.1-cp38-cp38-macosx_10_9_x86_64.whl (23.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 23.9 MB 995 kB/s eta 0:00:01    |███████▋                        | 5.7 MB 1.5 MB/s eta 0:00:12     |████████████████████████▉       | 18.5 MB 416 kB/s eta 0:00:13\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /opt/anaconda3/lib/python3.8/site-packages (from gensim) (1.18.5)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /opt/anaconda3/lib/python3.8/site-packages (from gensim) (1.4.1)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading smart_open-5.0.0-py3-none-any.whl (56 kB)\n",
      "\u001b[K     |████████████████████████████████| 56 kB 228 kB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: smart-open, gensim\n",
      "Successfully installed gensim-4.0.1 smart-open-5.0.0\n",
      "\u001b[33mWARNING: You are using pip version 20.3.3; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after extracting the model is 3.64 gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_w2v = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin',binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelw2v.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Bhutan', 0.8170939683914185),\n",
       " ('Nepali', 0.781296968460083),\n",
       " ('Nepalese', 0.7759099006652832),\n",
       " ('Kathmandu', 0.734721839427948),\n",
       " ('Himalayan_kingdom', 0.7084589004516602),\n",
       " ('Bhattarai', 0.7057297825813293),\n",
       " ('Thapa', 0.6967089176177979),\n",
       " ('Bhutanese', 0.6812286972999573),\n",
       " ('Dahal', 0.6810930371284485),\n",
       " ('Pokhara', 0.6747621297836304)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('Nepal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip-gram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying to predict a context word when a target word is taken as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# window_size --- When the window size is defined as 5, the model takes in two words from the left and two words from the \n",
    "# right of the target word as the context words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Training word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [['I','am','trying','to','understand','Natural','Language','Processing'],\n",
    "            ['Natural','Language','Processing','is','fun','to','learn'],\n",
    "            ['There','are','numerous','use','cases','of','Natural','Language','Processing']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences,min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The value of min_count sets a minimum threshold so that vectors are built only for words that occur more \n",
    "# often than the value specified in the min_count parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.wv.key_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our vocabulary has a size of 17\n",
    "# equal to number of unique words in the sentence we have defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Processing': 0,\n",
       " 'Natural': 1,\n",
       " 'Language': 2,\n",
       " 'to': 3,\n",
       " 'of': 4,\n",
       " 'am': 5,\n",
       " 'trying': 6,\n",
       " 'understand': 7,\n",
       " 'is': 8,\n",
       " 'cases': 9,\n",
       " 'fun': 10,\n",
       " 'learn': 11,\n",
       " 'There': 12,\n",
       " 'are': 13,\n",
       " 'numerous': 14,\n",
       " 'use': 15,\n",
       " 'I': 16}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.key_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modifying min_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences,min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Processing': 0, 'Language': 1, 'Natural': 2, 'to': 3}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.key_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Higher-dimensional vectors capture more information across dimensions, \n",
    "# especially when the corpus and vocabulary are big and the data is highly varied.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# playing with the vector size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences,min_count=2,vector_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each of the four words that occur more than once is now represented using 300 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other parameters \n",
    "# sg =1 , uses skip-gram and if sg=0 uses CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# negative = if value is greteaer than 1 signoifeis negative samples to use\n",
    "# the interger value signifies number of negative samples to use\n",
    "\n",
    "# workers = numbers of threads to use for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('modelw2v.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Applications of Word2vec\n",
    "\n",
    "# document similarity or how related two or more documents are to each other\n",
    "# search engines, building classification, and clustering models where sentences can be represented by \n",
    "# using embeddings of the words in them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Mover's Distance (WMD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyemd\n",
      "  Downloading pyemd-0.5.1.tar.gz (91 kB)\n",
      "\u001b[K     |████████████████████████████████| 91 kB 329 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.9.0 in /opt/anaconda3/lib/python3.8/site-packages (from pyemd) (1.18.5)\n",
      "Building wheels for collected packages: pyemd\n",
      "  Building wheel for pyemd (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyemd: filename=pyemd-0.5.1-cp38-cp38-macosx_10_9_x86_64.whl size=78955 sha256=b94803d1445786a8e160bd9f76b81d4ecaf5ff1aeb3566f781e000eb36e16f1c\n",
      "  Stored in directory: /Users/aayush/Library/Caches/pip/wheels/a2/a5/34/f960a47ca5c06b0e91b6f48117a79a66f53a879f8fac9529bf\n",
      "Successfully built pyemd\n",
      "Installing collected packages: pyemd\n",
      "Successfully installed pyemd-0.5.1\n",
      "\u001b[33mWARNING: You are using pip version 20.3.3; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install pyemd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyemd import emd\n",
    "# from gensim.similarities import WmdSimilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for document similarity\n",
    "# for finding resumes similar to a job description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dissimilarity between two text documents as the minimum amount of distance that the embedded words of one document need to \n",
    "# travel to reach the embedded words of another document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_w2v = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin',binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1= \"Obama speaks to the media in Illinois\"\n",
    "sentence2 = \"President greets the press in Chicago\"\n",
    "sentence3 = \"Apple is my favorite company\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4277553083600646"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance1 = model_w2v.wmdistance(sentence1,sentence2)\n",
    "distance1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# least the distance, more is the similarity between them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47793400675650705"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance2 = model_w2v.wmdistance(sentence1,sentence3)\n",
    "distance2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5709657015168149"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance3 = model_w2v.wmdistance(sentence2,sentence3)\n",
    "distance3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
