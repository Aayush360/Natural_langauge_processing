{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are some important things to consider while creating and deploying the sentiment analyzer:\n",
    "The training data should be consistent with the objective of the sentiment analyzer. Don't train the model using movie reviews if the objective is to predict the sentiment of financial news articles.\n",
    "\n",
    "\n",
    "Accurately labeling the training data is critical for the model to perform well. We have used pre-labeled data in this chapter. However, if you are creating a real- world application, you will have to spend time labeling the training documents. Typically, labeling should be done by someone with a good understanding of industry jargon.\n",
    "\n",
    "\n",
    "Sourcing training data is a difficult task. You can use tools such as web scraping or social media scraping, subject to permissions. Effort should be spent on sourcing data from multiple platforms and you shouldn't rely too much on a particular source.\n",
    "\n",
    "\n",
    "Evaluate the performance of your model regularly and retrain the model if required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment analysis: opinion mining/polarity detection\n",
    "# extract the polarity of a given document (+,-,NEUTRAL)\n",
    "# large group of users or potential customers in a cost-efficient way.\n",
    "\n",
    "# advertisement campaigns, political campaigns, stock analysis, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $ [Url]:(http://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences) $\n",
    "#### As we can see, the document contains a list of customer reviews and each review is assigned a sentiment score, \n",
    "#### with 0 representing negative sentiment and 1 representing positive sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('amazon_cells_labelled.txt',sep='\\t',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  1\n",
       "0  So there is no way for me to plug it in here i...  0\n",
       "1                        Good case, Excellent value.  1\n",
       "2                             Great for the jawbone.  1\n",
       "3  Tied to charger for conversations lasting more...  0\n",
       "4                                  The mic is great.  1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,0] # extract columns with reviews\n",
    "y = data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      So there is no way for me to plug it in here i...\n",
       "1                            Good case, Excellent value.\n",
       "2                                 Great for the jawbone.\n",
       "3      Tied to charger for conversations lasting more...\n",
       "4                                      The mic is great.\n",
       "                             ...                        \n",
       "995    The screen does get smudged easily because it ...\n",
       "996    What a piece of junk.. I lose more calls on th...\n",
       "997                         Item Does Not Match Picture.\n",
       "998    The only thing that disappoint me is the infra...\n",
       "999    You can not answer calls with the unit, never ...\n",
       "Name: 0, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CountVectorizer class, which performs key preprocessing steps on the text data such as tokenization, \n",
    "# stop word removal, one-hot encoding, and so on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1000x1642 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 4702 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X_vec = vectorizer.fit_transform(X)\n",
    "X_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10', '100', '11', '12', '13', '15', '15g', '18', '20', '2000', '2005', '2160', '24', '2mp', '325', '350', '375', '3o', '42', '44', '45', '4s', '50', '5020', '510', '5320', '680', '700w', '8125', '8525', '8530', 'abhor', 'ability', 'able', 'abound', 'absolutel', 'absolutely', 'ac', 'accept', 'acceptable', 'access', 'accessable', 'accessing', 'accessory', 'accessoryone', 'accidentally', 'accompanied', 'according', 'activate', 'activated', 'activesync', 'actually', 'ad', 'adapter', 'adapters', 'add', 'addition', 'additional', 'address', 'adhesive', 'adorable', 'advertised', 'advise', 'aggravating', 'ago', 'alarm', 'allot', 'allow', 'allowing', 'allows', 'alot', 'aluminum', 'amazed', 'amazing', 'amazon', 'amp', 'ample', 'angeles', 'angle', 'answer', 'ant', 'antena', 'anti', 'apart', 'apartment', 'apparently', 'appealing', 'appearance', 'appears', 'applifies', 'appointments', 'area', 'arguing', 'armband', 'arrival', 'arrived', 'asia', 'ask', 'aspect', 'assumed', 'atleast', 'att', 'attacked', 'attractive', 'audio', 'authentic', 'auto', 'available', 'average', 'avoid', 'avoiding', 'away', 'awesome', 'awful', 'awkward', 'awsome', 'background', 'backlight', 'bad', 'balance', 'bar', 'barely', 'bargain', 'bars', 'basement', 'basic', 'basically', 'batteries', 'battery', 'beat', 'beats', 'beautiful', 'bed', 'beep', 'beeping', 'behing', 'believe', 'bells', 'belt', 'bend', 'best', 'better', 'beware', 'big', 'biggest', 'bills', 'bit', 'bitpim', 'black', 'blackberry', 'blacktop', 'bland', 'blew', 'blue', 'blueant', 'bluetoooth', 'bluetooth', 'bluetooths', 'bmw', 'book', 'booking', 'boost', 'boot', 'bose', 'bother', 'bottowm', 'bought', 'bougth', 'boy', 'brand', 'break', 'breakage', 'breaking', 'breaks', 'brilliant', 'broke', 'broken', 'browser', 'browsing', 'bt', 'bt250v', 'bt50', 'bubbling', 'bucks', 'buds', 'build', 'built', 'bulky', 'bumpers', 'button', 'buttons', 'buy', 'buyer', 'buyers', 'buying', 'buyit', 'buzzing', 'ca', 'cable', 'cables', 'calendar', 'called', 'calls', 'came', 'camera', 'canal', 'cancellation', 'cancelling', 'capability', 'capacity', 'car', 'card', 'care', 'careful', 'carried', 'carriers', 'carries', 'carry', 'case', 'cases', 'casing', 'cassette', 'cat', 'catching', 'caused', 'causing', 'cbr', 'cds', 'cell', 'cellphone', 'cellphones', 'cellular', 'cent', 'center', 'certain', 'certainly', 'changing', 'channel', 'charge', 'charged', 'charger', 'chargers', 'charges', 'charging', 'charm', 'cheap', 'cheaper', 'cheaply', 'cheapy', 'check', 'checked', 'child', 'china', 'chinese', 'choice', 'choices', 'christmas', 'cingulair', 'cingular', 'clarity', 'classy', 'clear', 'clearer', 'clearly', 'clever', 'clicks', 'clip', 'clipping', 'clips', 'clock', 'colleague', 'color', 'colored', 'colors', 'combination', 'come', 'comes', 'comfort', 'comfortable', 'comfortably', 'comfortible', 'coming', 'comments', 'commercials', 'communicate', 'communication', 'communications', 'commuter', 'company', 'comparably', 'compared', 'compete', 'competitors', 'complain', 'complained', 'complaint', 'complaints', 'completely', 'compliments', 'compromise', 'computer', 'concrete', 'conditions', 'confortable', 'confusing', 'connect', 'connected', 'connecting', 'connection', 'constantly', 'constructed', 'construction', 'consumer', 'contact', 'contacted', 'contacting', 'contacts', 'continue', 'continues', 'contract', 'control', 'controls', 'contstruct', 'convenient', 'conversation', 'conversations', 'converter', 'cool', 'copier', 'copy', 'corded', 'correctly', 'cost', 'costs', 'couldn', 'counter', 'counterfeit', 'couple', 'coupon', 'course', 'cover', 'coverage', 'covered', 'crack', 'cracked', 'cradle', 'cradles', 'crap', 'crappy', 'crashed', 'crawl', 'creaks', 'crisp', 'cumbersome', 'current', 'currently', 'curve', 'customer', 'cut', 'cute', 'cutouts', 'cuts', 'd807', 'damage', 'darn', 'data', 'date', 'day', 'days', 'dead', 'deaf', 'deal', 'decade', 'decent', 'decision', 'defeats', 'defect', 'defective', 'deffinitely', 'definitely', 'definitly', 'delay', 'delivery', 'described', 'description', 'design', 'designed', 'designs', 'despite', 'destination', 'destroying', 'detachable', 'detailed', 'development', 'device', 'devices', 'dialing', 'did', 'didn', 'died', 'dieing', 'different', 'difficult', 'directed', 'directions', 'directly', 'dirty', 'disapoinment', 'disapointing', 'disappoint', 'disappointed', 'disappointing', 'disappointment', 'discarded', 'discomfort', 'disconnected', 'discount', 'disgusting', 'display', 'displeased', 'disposable', 'dissapointed', 'dissapointing', 'distorted', 'distracting', 'dit', 'division', 'dna', 'docking', 'does', 'doesn', 'doing', 'dollar', 'don', 'dont', 'double', 'download', 'downloading', 'dozen', 'dozens', 'drain', 'drained', 'drains', 'drawback', 'driving', 'drivng', 'droid', 'drop', 'dropped', 'dropping', 'drops', 'dual', 'durable', 'dustpan', 'dying', 'e2', 'e715', 'ear', 'earbud', 'earbuds', 'earbugs', 'eargels', 'earlier', 'earpad', 'earphone', 'earphones', 'earpiece', 'earpieces', 'ears', 'earset', 'ease', 'easier', 'easily', 'easy', 'echo', 'edge', 'effect', 'effective', 'effects', 'effort', 'electronics', 'elegant', 'embarassing', 'embarrassing', 'embedded', 'encourage', 'end', 'ended', 'ends', 'engineered', 'enjoy', 'enter', 'entertainment', 'entire', 'env', 'equipment', 'era', 'ergonomic', 'ericson', 'ericsson', 'especially', 'essentially', 'europe', 'eventually', 'everyday', 'exactly', 'exceeds', 'excelent', 'excellent', 'excels', 'exceptional', 'excessive', 'exchange', 'exchanged', 'excited', 'exclaim', 'excrutiatingly', 'exercise', 'existing', 'expect', 'expectations', 'expected', 'expensive', 'experience', 'experienced', 'explain', 'extended', 'exterior', 'external', 'extra', 'extremely', 'eye', 'fabulous', 'face', 'faceplates', 'fact', 'factor', 'failed', 'fails', 'fairly', 'fall', 'falling', 'falls', 'family', 'fantastic', 'far', 'fast', 'faster', 'father', 'favorite', 'feature', 'features', 'fee', 'feel', 'feels', 'feet', 'felt', 'fi', 'figure', 'file', 'finally', 'finds', 'fine', 'fingers', 'finished', 'fit', 'fits', 'fixes', 'flash', 'flaw', 'flawed', 'flawless', 'flawlessly', 'flaws', 'flimsy', 'flip', 'flipphones', 'fliptop', 'floor', 'floppy', 'flops', 'flush', 'fm', 'followed', 'fond', 'fooled', 'forced', 'forever', 'forgeries', 'forget', 'forgot', 'form', 'fourth', 'fraction', 'free', 'freedom', 'freeway', 'freezes', 'frequently4', 'frequentyly', 'friendly', 'friends', 'frog', 'frustration', 'fry', 'ft', 'fulfills', 'fully', 'fun', 'function', 'functional', 'functionality', 'functions', 'funny', 'gadget', 'gadgets', 'games', 'garbage', 'garbled', 'gave', 'geeky', 'gels', 'generally', 'gentle', 'genuine', 'gets', 'getting', 'gimmick', 'girl', 'given', 'giving', 'glad', 'glare', 'glasses', 'glove', 'glued', 'goes', 'going', 'gonna', 'good', 'good7', 'gosh', 'got', 'gotten', 'graphics', 'great', 'greater', 'grey', 'grip', 'grtting', 'guess', 'gx2', 'h500', 'hair', 'hand', 'handheld', 'hands', 'handset', 'handsfree', 'handy', 'happened', 'happening', 'happens', 'happier', 'happy', 'hard', 'hardly', 'hat', 'hate', 'hated', 'haul', 'haven', 'having', 'headbands', 'headphones', 'headset', 'headsets', 'hear', 'hearing', 'heavy', 'help', 'helpful', 'hey', 'high', 'highest', 'highly', 'highy', 'hinge', 'hit', 'hitch', 'hold', 'holder', 'holding', 'holds', 'holster', 'home', 'hook', 'hoped', 'hoping', 'horrible', 'hot', 'hour', 'hours', 'hoursthe', 'house', 'hs850', 'huge', 'humans', 'humming', 'hurt', 'hybrid', 'hype', 'iam', 'idea', 'ideal', 'igo', 'ill', 'im', 'imac', 'images', 'imagine', 'immediately', 'important', 'impossible', 'impressed', 'impressive', 'improper', 'improve', 'improvement', 'inches', 'included', 'incoming', 'inconspicuous', 'increase', 'incrediable', 'incredible', 'incredibly', 'indoors', 'industrial', 'inexcusable', 'inexpensive', 'infatuated', 'inform', 'infra', 'infuriating', 'insert', 'inside', 'install', 'installed', 'instance', 'instead', 'instruction', 'instructions', 'integrated', 'intended', 'interested', 'interface', 'intermittently', 'internet', 'invented', 'investment', 'iphone', 'ipod', 'ipods', 'ir', 'irda', 'iriver', 'isn', 'issues', 'item', 'items', 'jabra', 'jabra350', 'jack', 'jawbone', 'jerks', 'jiggle', 'job', 'joke', 'joy', 'juice', 'junk', 'just', 'jx', 'keen', 'keeping', 'keeps', 'kept', 'key', 'keyboard', 'keypad', 'keypads', 'keys', 'killer', 'kind', 'kindle', 'kitchen', 'kits', 'knock', 'know', 'knows', 'krussel', 'l7c', 'lacking', 'land', 'lap', 'laptop', 'large', 'lasted', 'lasting', 'lasts', 'latch', 'lately', 'later', 'latest', 'laughing', 'leaf', 'leaks', 'learned', 'leather', 'left', 'lense', 'leopard', 'lesson', 'let', 'letting', 'lg', 'life', 'light', 'lightly', 'lights', 'lightweight', 'like', 'liked', 'likes', 'line', 'linked', 'linking', 'linksys', 'listener', 'listening', 'lit', 'literally', 'little', 'living', 'll', 'loads', 'lock', 'locked', 'locks', 'logitech', 'long', 'longer', 'look', 'looking', 'looks', 'loop', 'loops', 'loose', 'looses', 'los', 'lose', 'lost', 'lot', 'lots', 'loud', 'louder', 'loudest', 'loudspeaker', 'lousy', 'love', 'loved', 'loves', 'low', 'luck', 'machine', 'magical', 'magnetic', 'mail', 'mainly', 'maintain', 'maintains', 'major', 'majority', 'make', 'makes', 'making', 'managed', 'management', 'manual', 'manufacturer', 'mark', 'market', 'match', 'material', 'max', 'means', 'mechanism', 'media', 'mediocre', 'mega', 'megapixels', 'memory', 'mention', 'mentioned', 'menus', 'mere', 'mess', 'message', 'messages', 'messaging', 'messes', 'metal', 'metro', 'mic', 'microphone', 'microsoft', 'mind', 'mini', 'mins', 'minute', 'minutes', 'misleading', 'missed', 'mistake', 'mobile', 'mode', 'model', 'modest', 'money', 'monkeys', 'month', 'months', 'morning', 'mother', 'moto', 'motor', 'motorola', 'motorolas', 'moving', 'mp3', 'mp3s', 'muddy', 'muffled', 'multiple', 'music', 'mute', 'nano', 'navigate', 'near', 'nearly', 'neat', 'need', 'needed', 'needless', 'needs', 'negatively', 'network', 'new', 'ngage', 'nice', 'nicely', 'nicer', 'night', 'nightmare', 'noise', 'noises', 'nokia', 'normal', 'normally', 'note', 'noted', 'notice', 'noticed', 'number', 'numbers', 'numerous', 'nyc', 'obviously', 'occupied', 'odd', 'oem', 'offering', 'offers', 'official', 'oh', 'ok', 'old', 'ones', 'online', 'oozes', 'open', 'opens', 'operate', 'operates', 'optimal', 'option', 'options', 'order', 'ordered', 'ordering', 'orders', 'organizational', 'original', 'originally', 'os', 'outgoing', 'outlet', 'outperform', 'outside', 'overall', 'overly', 'overnight', 'overnite', 'override', 'owned', 'owner', 'owning', 'pack', 'package', 'packaged', 'pad', 'pads', 'pain', 'painful', 'pair', 'paired', 'pairing', 'palm', 'palms', 'palmtop', 'pants', 'particular', 'party', 'passed', 'patient', 'pause', 'pay', 'pc', 'pcs', 'pda', 'peachy', 'peeling', 'penny', 'pens', 'people', 'perfect', 'perfectly', 'performance', 'performed', 'performing', 'periodically', 'periods', 'person', 'petroleum', 'phone', 'phones', 'photo', 'pics', 'picture', 'pictures', 'piece', 'pitiful', 'pixel', 'place', 'placed', 'places', 'plan', 'planning', 'plans', 'plantronics', 'plantronincs', 'plastic', 'play', 'player', 'players', 'plays', 'pleasantly', 'pleased', 'pleather', 'plenty', 'plug', 'plugged', 'plugs', 'plus', 'pocket', 'pockets', 'point', 'poor', 'poorly', 'port', 'portable', 'portraits', 'possesed', 'possibility', 'posted', 'potentially', 'power', 'practical', 'practically', 'practice', 'preferably', 'premium', 'prettier', 'pretty', 'prevents', 'previous', 'price', 'priced', 'pricing', 'prime', 'print', 'probably', 'problem', 'problems', 'procedure', 'procedures', 'produce', 'product', 'products', 'program', 'promised', 'prompt', 'promptly', 'properly', 'pros', 'protected', 'protection', 'protective', 'protector', 'protects', 'provide', 'provided', 'provides', 'ps3', 'psyched', 'puff', 'pull', 'purcashed', 'purchase', 'purchased', 'purchases', 'purchasing', 'purpose', 'push', 'pushed', 'quality', 'quick', 'quickly', 'quiet', 'quit', 'quite', 'qwerty', 'r450', 'randomly', 'range', 'rare', 'rate', 'rated', 'rating', 'razor', 'razr', 'reach', 'reaching', 'read', 'reading', 'ready', 'real', 'realize', 'really', 'reason', 'reasonable', 'reasonably', 'reboots', 'reccomendation', 'reccommend', 'receipt', 'receive', 'received', 'receiving', 'recently', 'reception', 'recessed', 'recharge', 'recieve', 'recognition', 'recognizes', 'recommend', 'recommended', 'red', 'refund', 'refurb', 'refuse', 'refused', 'regarding', 'regret', 'regretted', 'relative', 'relatively', 'reliability', 'remorse', 'removing', 'renders', 'reoccure', 'replace', 'replaced', 'replacement', 'replacementr', 'requirements', 'research', 'resistant', 'resolution', 'respect', 'rest', 'restart', 'restocking', 'restored', 'rests', 'results', 'return', 'returned', 'returning', 'reverse', 'reversible', 'review', 'reviews', 'ride', 'right', 'riingtones', 'ring', 'ringer', 'ringing', 'ringtones', 'rip', 'ripped', 'risk', 'roam', 'rocketed', 'rocks', 'roles', 'room', 'rotating', 'row', 'rubber', 'run', 'runs', 's11', 's710a', 'saggy', 'said', 'samsung', 'sanyo', 'satisfied', 'satisifed', 'save', 'saved', 'say', 'saying', 'says', 'scary', 'sch', 'scratch', 'scratched', 'screen', 'screens', 'seamlessly', 'searched', 'seat', 'seconds', 'secure', 'securely', 'securly', 'seeen', 'seen', 'self', 'seller', 'send', 'sending', 'sensitive', 'sensor', 'sent', 'seperated', 'series', 'seriously', 'service', 'set', 'setting', 'setup', 'severe', 'sex', 'shape', 'share', 'sharp', 'shield', 'shifting', 'shine', 'shiny', 'shipment', 'shipped', 'shipping', 'shooters', 'short', 'shots', 'shouldn', 'shouldve', 'shouting', 'shows', 'sides', 'sight', 'signal', 'signals', 'significantly', 'signs', 'sim', 'simple', 'simpler', 'simply', 'sins', 'sister', 'sitting', 'situations', 'size', 'sizes', 'sketchy', 'skip', 'skype', 'sleek', 'slid', 'slide', 'slider', 'sliding', 'slim', 'slipping', 'slow', 'slowly', 'small', 'smallest', 'smartphone', 'smell', 'smoke', 'smoking', 'smoother', 'smoothly', 'smudged', 'snap', 'snug', 'soft', 'software', 'sold', 'solid', 'somewhat', 'son', 'songs', 'sony', 'soon', 'sooner', 'sorry', 'sos', 'sound', 'sounded', 'sounds', 'source', 'sources', 'soyo', 'span', 'speaker', 'speakerphone', 'specially', 'specs', 'speed', 'spinn', 'spring', 'sprint', 'stand', 'standard', 'star', 'stars', 'startac', 'started', 'starter', 'starts', 'state', 'stated', 'static', 'station', 'stay', 'stays', 'steep', 'steer', 'stereo', 'stop', 'stopped', 'stops', 'storage', 'store', 'strange', 'strap', 'stream', 'strength', 'stress', 'strip', 'strong', 'stuck', 'study', 'stuff', 'stupid', 'sturdiness', 'sturdy', 'styles', 'styling', 'stylish', 'submerged', 'sucked', 'sucks', 'sudden', 'suddenly', 'sunglasses', 'super', 'superb', 'superfast', 'supertooth', 'support', 'supposedly', 'suprised', 'sure', 'surefire', 'surprised', 'survived', 'sweetest', 'switch', 'swivel', 'sync', 'synchronization', 'takes', 'talk', 'talking', 'tape', 'tech', 'technology', 'telephone', 'tell', 'terrible', 'texas', 'text', 'thank', 'thanks', 'thats', 'theory', 'thereplacement', 'thing', 'things', 'think', 'thorn', 'thought', 'threw', 'thumbs', 'tick', 'ticking', 'tied', 'tight', 'time', 'timeframe', 'timely', 'times', 'tinny', 'tiny', 'tips', 'tmobile', 'toactivate', 'toast', 'today', 'toilet', 'told', 'tone', 'tones', 'took', 'tool', 'tools', 'tooth', 'total', 'totally', 'touch', 'touches', 'tracfone', 'tracfonewebsite', 'tracking', 'transceiver', 'transfer', 'transformed', 'transmission', 'transmit', 'transmitters', 'trash', 'travled', 'tremendous', 'treo', 'tricky', 'tried', 'tries', 'trouble', 'truly', 'trunk', 'trust', 'try', 'trying', 'tungsten', 'turn', 'turned', 'turns', 'tv', 'type', 'ugly', 'unacceptable', 'unacceptible', 'unbearable', 'uncomfortable', 'understand', 'understanding', 'unfortunately', 'unhappy', 'unintelligible', 'unit', 'units', 'unknown', 'unless', 'unlike', 'unreliable', 'unsatisfactory', 'unusable', 'upbeat', 'update', 'upgrade', 'upload', 'upstairs', 'usable', 'usage', 'usb', 'use', 'used', 'useful', 'usefulness', 'useless', 'user', 'using', 'usually', 'utter', 'utterly', 'v1', 'v265', 'v325i', 'v3c', 'v3i', 'value', 've', 'vehicle', 'verizon', 'video', 'videos', 'virgin', 'visor', 'voice', 'voltage', 'volume', 'vx', 'vx9900', 'w810i', 'waaay', 'waiting', 'wake', 'walked', 'walkman', 'wall', 'wallet', 'want', 'wanted', 'warning', 'warranty', 'wasn', 'waste', 'wasted', 'wasting', 'waterproof', 'way', 'weak', 'wear', 'wearing', 'web', 'website', 'websites', 'week', 'weeks', 'weight', 'weird', 'went', 'whatsoever', 'whine', 'whistles', 'white', 'whoa', 'wi', 'wife', 'wild', 'wind', 'window', 'windows', 'winner', 'wiping', 'wire', 'wired', 'wirefly', 'wireless', 'wise', 'wish', 'wit', 'wobbly', 'won', 'wonder', 'wonderfully', 'wont', 'wood', 'wooden', 'word', 'work', 'worked', 'working', 'works', 'world', 'worn', 'worst', 'worth', 'worthless', 'worthwhile', 'wouldn', 'wow', 'wrong', 'wrongly', 'year', 'years', 'yell', 'yes', 'z500a', 'zero']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1642"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_vec.todense() # convert sparse matrix to dense matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each row vector represents the word count in that row for each unique word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the word count matrix into a matrix with corresponding tf-idf values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Transform data by applying term frequency inverse document frequency (TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf = tfidf.fit_transform(X_vec)\n",
    "X_tfidf = X_tfidf.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# because each review in the corpus is quite brief, the majority of the values in each row of the matrix are set to 0:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X_tfidf,y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the training data essentially means that our Naive Bayes classifier has now learned the training data and is now in a position to calculate relevant probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 87,  33],\n",
       "       [ 20, 110]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  The vertical axis of sklearn's confusion matrix should be interpreted as the actual values, \n",
    "# while the horizontal axis should be interpreted as the predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Therefore, the accuracy, in this case, is 197/250 = 78.8%.\n",
    "# This is a decent accuracy score given the simple model and limited training data we had (only 750 abridged reviews)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning model parameters and performing further preprocessing steps such as lemmatization, stemming, and so on can \n",
    "# improve the accuracy further.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimal hyperplane that best segregates the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  SVM identifies the frontier data points (or points closest to the opposing class), also known as support vectors, \n",
    "# and then attempts to find the boundary (also known as the hyperplane in the N-dimensional space)\n",
    "# that is the farthest from the support vector of each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To identify a hyperplane that segregates vectors in a 1,642-dimensional space into\n",
    "# positive sentiment classes and negative sentiment classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1642)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tfidf.shape # 1642 is the number of features and we have 1000 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = SVC(kernel='linear')\n",
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier has identified the optimum hyperplane after identifying the \n",
    "# frontier points and calculating the relevant distances based on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# measure the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[102,  18],\n",
       "       [ 33,  97]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  the accuracy, in this case, 199/250 = 79.6%, which is marginally better than the Naive Bayes model's accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# he model's performance can be further improved by improving input data preprocessing (via lemmatization, stemming, and so on) \n",
    "# and optimizing various SVM hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_rbf = SVC(kernel='rbf')\n",
    "classifier_rbf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier_rbf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[106,  14],\n",
       "       [ 45,  85]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy = 76.4%, worse than linear classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Productinizing a trained sentiment analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# way to reuse this model to predict the sentiment of new product reviews. \n",
    "# picking means - efers to serializing and deserializing Python object structures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(vectorizer,open('vectorizer','wb')) # save vectorizer for resue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(classifier,open('svm_clf_sa','wb')) # save the classifier for resue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(clf,open('nb_clf','wb')) # save the classifier for resue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can now import these pickled objects as we wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a function that does the job of classifying the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis(classifier,training_matrix,doc):\n",
    "    '''function to predict the sentiment of product review\n",
    "    classifier: pre_trained_model\n",
    "    training_matrix: matrix of features assosoated with trained model (vectorizer)\n",
    "    doc: product review whose sentiment needs to be classified'''\n",
    "    X_new = training_matrix.transform(pd.Series(doc))\n",
    "    # dont use fit transform here as model is already fitted\n",
    "    X_new = X_new.todense() # convert sparse matrix to dense\n",
    "    \n",
    "    from sklearn.feature_extraction.text import TfidfTransformer\n",
    "    tfidf = TfidfTransformer()\n",
    "    X_tfidf_new = tfidf.fit_transform(X_new)\n",
    "    X_tfidf_new = X_tfidf_new.todense()\n",
    "    y_new = classifier.predict(X_tfidf_new)\n",
    "    if y_new==0:\n",
    "        return 'negative sentiment'\n",
    "    elif y_new==1:\n",
    "        return 'positive sentiment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upickling the pickled model and vectorizer and pass to the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf = pickle.load(open('nb_clf','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = pickle.load(open('vectorizer','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_doc = \"The battery performance is not as expected .\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative sentiment'"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_analysis(svm_clf,vectorizer,new_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    " new_doc = \"I dont think i like this product\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative sentiment'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_analysis(svm_clf,vectorizer,new_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the performance of your model regularly and retrain the model if required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
